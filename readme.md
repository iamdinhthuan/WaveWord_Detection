# Wake Word Detection - "Hey DT"

Há»‡ thá»‘ng nháº­n diá»‡n tá»« Ä‘Ã¡nh thá»©c "Hey DT" sá»­ dá»¥ng deep learning vá»›i kháº£ nÄƒng xá»­ lÃ½ real-time vÃ  audio augmentation tiÃªn tiáº¿n.

## ğŸ¯ Tá»•ng quan

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng wake word detection cÃ³ thá»ƒ nháº­n diá»‡n cá»¥m tá»« "Hey DT" trong thá»i gian thá»±c. Há»‡ thá»‘ng sá»­ dá»¥ng mÃ´ hÃ¬nh CNN-LSTM káº¿t há»£p vá»›i Voice Activity Detection (VAD) Ä‘á»ƒ Ä‘áº¡t hiá»‡u suáº¥t cao vÃ  giáº£m false positive.

### âœ¨ TÃ­nh nÄƒng chÃ­nh

- **Real-time Detection**: Nháº­n diá»‡n wake word trong thá»i gian thá»±c
- **Advanced Audio Augmentation**: TÄƒng cÆ°á»ng dá»¯ liá»‡u vá»›i noise thá»±c táº¿, speed perturbation, volume control
- **Voice Activity Detection**: Sá»­ dá»¥ng WebRTC VAD Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t
- **Enhanced CNN-LSTM Architecture**: Kiáº¿n trÃºc deep learning vá»›i BatchNormalization vÃ  Dropout
- **Comprehensive Evaluation**: ÄÃ¡nh giÃ¡ chi tiáº¿t vá»›i confusion matrix vÃ  metrics

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### Dependencies

```bash
pip install -r requirements.txt
```

### Cáº¥u trÃºc thÆ° má»¥c

```
project/
â”œâ”€â”€ train.py                 # Script training model
â”œâ”€â”€ predict.py              # Script real-time detection
â”œâ”€â”€ dir_folder_data/        # ThÆ° má»¥c chá»©a dá»¯ liá»‡u training
â”‚   â”œâ”€â”€ wakeword/          # Audio files "Hey DT" (.wav)
â”‚   â””â”€â”€ non-wakeword/      # Audio files khÃ´ng pháº£i wake word (.wav)
â”œâ”€â”€ dir_noise_audio/       # ThÆ° má»¥c chá»©a noise files (optional)
â”œâ”€â”€ wakeword_model.h5      # Model Ä‘Ã£ train (output)
â””â”€â”€ README.md
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Chuáº©n bá»‹ dá»¯ liá»‡u

#### Dá»¯ liá»‡u Wake Word ("Hey DT")
- Táº¡o thÆ° má»¥c `dir_folder_data/wakeword/`
- Thu tháº­p audio files chá»©a cá»¥m tá»« "Hey DT"
- Format: `.wav`, sample rate 16kHz, mono
- Khuyáº¿n nghá»‹: Ã­t nháº¥t 100-200 samples tá»« nhiá»u ngÆ°á»i nÃ³i khÃ¡c nhau

#### Dá»¯ liá»‡u Non-Wake Word
- Táº¡o thÆ° má»¥c `dir_folder_data/non-wakeword/`
- Thu tháº­p audio files khÃ´ng chá»©a "Hey DT"
- CÃ³ thá»ƒ bao gá»“m: tiáº¿ng á»“n, Ã¢m thanh mÃ´i trÆ°á»ng, cÃ¡c tá»« khÃ¡c
- Khuyáº¿n nghá»‹: gáº¥p 2-3 láº§n sá»‘ lÆ°á»£ng wake word samples

#### Noise Files (TÃ¹y chá»n)
- Táº¡o thÆ° má»¥c `dir_noise_audio/`
- Chá»©a cÃ¡c file audio noise Ä‘á»ƒ augmentation
- Format: `.wav`, `.mp3`, `.flac`, etc.

### 2. Training Model

```bash
python train.py
```

#### Cáº¥u hÃ¬nh Training

Chá»‰nh sá»­a cÃ¡c tham sá»‘ trong `train.py`:

```python
# Configuration
AUDIO_DIR = "dir_folder_data"      # ThÆ° má»¥c chá»©a dá»¯ liá»‡u
NOISE_DIR = "dir_noise_audio"      # ThÆ° má»¥c noise (cÃ³ thá»ƒ Ä‘á»ƒ None)
MODEL_PATH = "wakeword_model.h5"   # ÄÆ°á»ng dáº«n lÆ°u model

# Augmentation parameters
augmentation_factor = 2            # Sá»‘ augmented samples cho má»—i original
```

#### QuÃ¡ trÃ¬nh Training

1. **Data Loading**: Load vÃ  xá»­ lÃ½ audio files
2. **Audio Augmentation**: Ãp dá»¥ng cÃ¡c ká»¹ thuáº­t augmentation
3. **Feature Extraction**: TrÃ­ch xuáº¥t MFCC features (13 coefficients)
4. **Model Training**: Train CNN-LSTM model vá»›i early stopping
5. **Evaluation**: ÄÃ¡nh giÃ¡ model vá»›i confusion matrix vÃ  metrics

#### Káº¿t quáº£ Training

- Model file: `wakeword_model.h5`
- Training log: `training_log.csv`
- Analysis plot: `enhanced_training_analysis.png`
- Console output vá»›i detailed metrics

### 3. Real-time Detection

```bash
python predict.py
```

#### Cáº¥u hÃ¬nh Detection

Chá»‰nh sá»­a cÃ¡c tham sá»‘ trong `predict.py`:

```python
MODEL_PATH = "wakeword_model.h5"   # ÄÆ°á»ng dáº«n model
SAMPLE_RATE = 16000                # Sample rate
WAKE_THRESHOLD = 0.5               # NgÆ°á»¡ng detection (0.0-1.0)
VAD_AGGRESSIVENESS = 1             # Äá»™ nháº¡y VAD (0-3)
```

#### Hoáº¡t Ä‘á»™ng

1. **Audio Streaming**: Capture audio tá»« microphone
2. **Voice Activity Detection**: PhÃ¡t hiá»‡n pháº§n audio cÃ³ voice
3. **Feature Extraction**: TrÃ­ch xuáº¥t MFCC features
4. **Wake Word Detection**: Predict confidence score
5. **Threshold Check**: So sÃ¡nh vá»›i ngÆ°á»¡ng Ä‘á»ƒ quyáº¿t Ä‘á»‹nh

## âš™ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

### Audio Augmentation

- **Real Noise Addition**: ThÃªm noise thá»±c táº¿ vá»›i SNR control
- **Gaussian Noise**: ThÃªm white noise
- **Time Shift**: Dá»‹ch chuyá»ƒn temporal
- **Speed Perturbation**: Thay Ä‘á»•i tá»‘c Ä‘á»™ (0.9x - 1.1x)
- **Volume Perturbation**: Thay Ä‘á»•i Ã¢m lÆ°á»£ng (0.7x - 1.3x)

### Model Architecture

```
Input: MFCC Features (time_steps, 13)
â”œâ”€â”€ Conv1D(16, kernel_size=5) + BatchNorm + MaxPool + Dropout
â”œâ”€â”€ Conv1D(32, kernel_size=5) + BatchNorm + MaxPool + Dropout
â”œâ”€â”€ LSTM(32, return_sequences=True) + Dropout
â”œâ”€â”€ LSTM(16) + Dropout
â”œâ”€â”€ Dense(32, relu) + Dropout
â””â”€â”€ Dense(1, sigmoid) -> Wake Word Probability
```

### Real-time Processing

- **Audio Streaming**: 480 samples/chunk (30ms at 16kHz)
- **VAD Processing**: WebRTC VAD cho speech detection
- **Buffer Management**: 3-second sliding window
- **Threading**: Separate threads cho audio capture vÃ  processing

## ğŸ“Š ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t

### Metrics

- **Accuracy**: Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
- **Precision**: Tá»· lá»‡ true positive trong predicted positive
- **Recall**: Tá»· lá»‡ true positive Ä‘Æ°á»£c detect
- **Specificity**: Tá»· lá»‡ true negative Ä‘Æ°á»£c detect chÃ­nh xÃ¡c
- **F1 Score**: Harmonic mean cá»§a precision vÃ  recall

### Confusion Matrix

```
                Predicted
              No    Yes
Actual No   [TN]  [FP]
       Yes  [FN]  [TP]
```

## ğŸ”§ Tá»‘i Æ°u hÃ³a

### Cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c

1. **TÄƒng dá»¯ liá»‡u training**:
   - Thu tháº­p thÃªm samples tá»« nhiá»u ngÆ°á»i nÃ³i
   - Äa dáº¡ng hÃ³a mÃ´i trÆ°á»ng ghi Ã¢m
   - ThÃªm variations cá»§a "Hey DT"

2. **Äiá»u chá»‰nh threshold**:
   - Giáº£m threshold: TÄƒng recall, giáº£m precision
   - TÄƒng threshold: TÄƒng precision, giáº£m recall

3. **Fine-tuning model**:
   - Äiá»u chá»‰nh architecture (sá»‘ layers, units)
   - Thay Ä‘á»•i learning rate vÃ  optimizer
   - ThÃªm regularization techniques

### Giáº£m latency

1. **Tá»‘i Æ°u audio processing**:
   - Giáº£m chunk size
   - Tá»‘i Æ°u feature extraction

2. **Model optimization**:
   - Model quantization
   - TensorFlow Lite conversion

## ğŸ›ï¸ Configuration Options

### Training Configuration

```python
class AugmentationConfig:
    def __init__(self):
        # Noise augmentation
        self.noise_snr_range = [5, 20]        # SNR range in dB
        self.gaussian_noise_level = 0.005     # Gaussian noise level
        
        # Time and speed augmentation
        self.time_shift_max = 0.1             # 10% of audio length
        self.speed_range = [0.9, 1.1]         # Speed factor range
        self.volume_range = [0.7, 1.3]        # Volume factor range
        
        # Augmentation probability
        self.augmentation_prob = 0.5          # Probability per augmentation
```

### Detection Configuration

```python
# Real-time detection parameters
sample_rate = 16000          # Audio sample rate
chunk_size = 480            # Audio chunk size (30ms)
wake_threshold = 0.5        # Wake word detection threshold
vad_aggressiveness = 1      # VAD sensitivity (0-3)
```

### Debug Mode

ThÃªm logging Ä‘á»ƒ debug:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“ Notes

- Model hoáº¡t Ä‘á»™ng tá»‘t nháº¥t vá»›i audio 16kHz, mono
- Khuyáº¿n nghá»‹ sá»­ dá»¥ng headset microphone Ä‘á»ƒ giáº£m echo
- Threshold máº·c Ä‘á»‹nh 0.5 phÃ¹ há»£p cho háº§u háº¿t trÆ°á»ng há»£p
- VAD aggressiveness cao (3) nháº¡y hÆ¡n nhÆ°ng cÃ³ thá»ƒ tÄƒng false positive


